{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# including total acc and gyroscope signals too, will stick to np for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.stats as st\n",
    "from scipy.fftpack import fft, fftfreq\n",
    "from scipy.signal import argrelextrema\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load body acceleration raw signals \n",
    "# x axis\n",
    "body_acc_x_train = np.loadtxt('./HARDataset/train/Inertial Signals/body_acc_x_train.txt')\n",
    "body_acc_x_test = np.loadtxt('./HARDataset/test/Inertial Signals/body_acc_x_test.txt')\n",
    "# y axis\n",
    "body_acc_y_train = np.loadtxt('./HARDataset/train/Inertial Signals/body_acc_y_train.txt')\n",
    "body_acc_y_test = np.loadtxt('./HARDataset/test/Inertial Signals/body_acc_y_test.txt')\n",
    "# z axis\n",
    "body_acc_z_train = np.loadtxt('./HARDataset/train/Inertial Signals/body_acc_z_train.txt')\n",
    "body_acc_z_test = np.loadtxt('./HARDataset/test/Inertial Signals/body_acc_z_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load total acceleration raw signals \n",
    "# x axis\n",
    "total_acc_x_train = np.loadtxt('./HARDataset/train/Inertial Signals/total_acc_x_train.txt')\n",
    "total_acc_x_test = np.loadtxt('./HARDataset/test/Inertial Signals/total_acc_x_test.txt')\n",
    "# y axis\n",
    "total_acc_y_train = np.loadtxt('./HARDataset/train/Inertial Signals/total_acc_y_train.txt')\n",
    "total_acc_y_test = np.loadtxt('./HARDataset/test/Inertial Signals/total_acc_y_test.txt')\n",
    "# z axis\n",
    "total_acc_z_train = np.loadtxt('./HARDataset/train/Inertial Signals/total_acc_z_train.txt')\n",
    "total_acc_z_test = np.loadtxt('./HARDataset/test/Inertial Signals/total_acc_z_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load body gyroscope raw signals \n",
    "# x axis\n",
    "body_gyro_x_train = np.loadtxt('./HARDataset/train/Inertial Signals/body_gyro_x_train.txt')\n",
    "body_gyro_x_test = np.loadtxt('./HARDataset/test/Inertial Signals/body_gyro_x_test.txt')\n",
    "# y axis\n",
    "body_gyro_y_train = np.loadtxt('./HARDataset/train/Inertial Signals/body_gyro_y_train.txt')\n",
    "body_gyro_y_test = np.loadtxt('./HARDataset/test/Inertial Signals/body_gyro_y_test.txt')\n",
    "# z axis\n",
    "body_gyro_z_train = np.loadtxt('./HARDataset/train/Inertial Signals/body_gyro_z_train.txt')\n",
    "body_gyro_z_test = np.loadtxt('./HARDataset/test/Inertial Signals/body_gyro_z_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 128), (2947, 128))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_acc_x_train.shape, body_acc_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 128), (2947, 128))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_acc_x_train.shape, total_acc_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 128), (2947, 128))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_gyro_x_train.shape, body_gyro_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load label vectors\n",
    "y_train = np.loadtxt('./HARDataset/train/y_train.txt')\n",
    "y_test = np.loadtxt('./HARDataset/test/y_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352,), (2947,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['Walking', 'Walking upstairs', 'Walking downstairs', 'Sitting', 'Standing', 'Laying']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_area_features(x, Te=1.0):\n",
    "    # mean\n",
    "    mean_ts = np.mean(x, axis=1).reshape(-1, 1)\n",
    "    # max\n",
    "    max_ts = np.amax(x, axis=1).reshape(-1, 1)\n",
    "    # min\n",
    "    min_ts = np.amin(x, axis=1).reshape(-1, 1)\n",
    "    # std\n",
    "    std_ts = np.std(x, axis=1).reshape(-1, 1)\n",
    "    # skew\n",
    "    skew_ts = st.skew(x, axis=1).reshape(-1, 1)\n",
    "    # kurtosis\n",
    "    kurtosis_ts = st.kurtosis(x, axis=1).reshape(-1, 1)\n",
    "    # interquartile range\n",
    "    iqr_ts = st.iqr(x, axis=1).reshape(-1, 1)\n",
    "    # median absolute deviation\n",
    "    mad_ts = np.median(np.sort(abs(x - np.mean(x, axis=1).reshape(-1, 1)), axis=1), axis=1).reshape(-1, 1)\n",
    "    # area under curve\n",
    "    area_ts = np.trapz(x, axis=1, dx=Te).reshape(-1, 1)\n",
    "    # area under curve ** 2\n",
    "    sq_area_ts = np.trapz(x ** 2, axis=1, dx=Te).reshape(-1, 1)\n",
    "    \n",
    "    return np.concatenate((mean_ts, max_ts, min_ts, std_ts, skew_ts, kurtosis_ts, iqr_ts, \n",
    "                           mad_ts, area_ts, sq_area_ts), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_acc_x_train_stats = stat_area_features(body_acc_x_train)\n",
    "body_acc_y_train_stats = stat_area_features(body_acc_y_train)\n",
    "body_acc_z_train_stats = stat_area_features(body_acc_z_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 10), (7352, 10), (7352, 10))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_acc_x_train_stats.shape, body_acc_y_train_stats.shape, body_acc_z_train_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc_x_train_stats = stat_area_features(total_acc_x_train)\n",
    "total_acc_y_train_stats = stat_area_features(total_acc_y_train)\n",
    "total_acc_z_train_stats = stat_area_features(total_acc_z_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 10), (7352, 10), (7352, 10))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_acc_x_train_stats.shape, total_acc_y_train_stats.shape, total_acc_z_train_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_gyro_x_train_stats = stat_area_features(body_gyro_x_train)\n",
    "body_gyro_y_train_stats = stat_area_features(body_gyro_y_train)\n",
    "body_gyro_z_train_stats = stat_area_features(body_gyro_z_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 10), (7352, 10), (7352, 10))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_gyro_x_train_stats.shape, body_gyro_y_train_stats.shape, body_gyro_z_train_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_acc_x_test_stats = stat_area_features(body_acc_x_test)\n",
    "body_acc_y_test_stats = stat_area_features(body_acc_y_test)\n",
    "body_acc_z_test_stats = stat_area_features(body_acc_z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2947, 10), (2947, 10), (2947, 10))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_acc_x_test_stats.shape, body_acc_y_test_stats.shape, body_acc_z_test_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc_x_test_stats = stat_area_features(total_acc_x_test)\n",
    "total_acc_y_test_stats = stat_area_features(total_acc_y_test)\n",
    "total_acc_z_test_stats = stat_area_features(total_acc_z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2947, 10), (2947, 10), (2947, 10))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_acc_x_test_stats.shape, total_acc_y_test_stats.shape, total_acc_z_test_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_gyro_x_test_stats = stat_area_features(body_gyro_x_test)\n",
    "body_gyro_y_test_stats = stat_area_features(body_gyro_y_test)\n",
    "body_gyro_z_test_stats = stat_area_features(body_gyro_z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2947, 10), (2947, 10), (2947, 10))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_gyro_x_test_stats.shape, body_gyro_y_test_stats.shape, body_gyro_z_test_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating X_train and X_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((body_acc_x_train_stats, body_acc_y_train_stats, body_acc_z_train_stats, \n",
    "                          total_acc_x_train_stats, total_acc_y_train_stats, total_acc_z_train_stats, \n",
    "                          body_gyro_x_train_stats, body_gyro_y_train_stats, body_gyro_z_train_stats), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate((body_acc_x_test_stats, body_acc_y_test_stats, body_acc_z_test_stats, \n",
    "                          total_acc_x_test_stats, total_acc_y_test_stats, total_acc_z_test_stats, \n",
    "                          body_gyro_x_test_stats, body_gyro_y_test_stats, body_gyro_z_test_stats), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 90), (2947, 90))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling data makes big differnce! to all! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can one do a simple log reg first?\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9530739934711643"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_logreg = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.82      0.76      0.79       496\n",
      "         2.0       0.82      0.76      0.79       471\n",
      "         3.0       0.76      0.93      0.84       420\n",
      "         4.0       0.88      0.90      0.89       491\n",
      "         5.0       0.90      0.89      0.90       532\n",
      "         6.0       1.00      0.95      0.97       537\n",
      "\n",
      "    accuracy                           0.87      2947\n",
      "   macro avg       0.86      0.87      0.86      2947\n",
      "weighted avg       0.87      0.87      0.87      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9581066376496191"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.85      0.83      0.84       496\n",
      "         2.0       0.85      0.86      0.86       471\n",
      "         3.0       0.91      0.93      0.92       420\n",
      "         4.0       0.81      0.82      0.82       491\n",
      "         5.0       0.85      0.82      0.83       532\n",
      "         6.0       0.97      1.00      0.98       537\n",
      "\n",
      "    accuracy                           0.88      2947\n",
      "   macro avg       0.87      0.88      0.88      2947\n",
      "weighted avg       0.88      0.88      0.88      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfc = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.76      0.79      0.77       496\n",
      "         2.0       0.82      0.79      0.80       471\n",
      "         3.0       0.89      0.89      0.89       420\n",
      "         4.0       0.81      0.92      0.86       491\n",
      "         5.0       0.92      0.80      0.86       532\n",
      "         6.0       1.00      1.00      1.00       537\n",
      "\n",
      "    accuracy                           0.87      2947\n",
      "   macro avg       0.87      0.87      0.86      2947\n",
      "weighted avg       0.87      0.87      0.87      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cool this got better - code still messy and can be improved - how? use functions? \n",
    "# add more features? perhaps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will quickly try out pca - to reduce dimenionality of dataset and then fit data \n",
    "# not sure this is particularly useful when i don't have soooo many dimensions in the data \n",
    "# but this is more for practice \n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.9) # to capture 90% of the variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8809847660500544"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# got worse! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9266866158868335"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also got worse! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfc_pca = rfc.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.48      0.49      0.48       496\n",
      "         2.0       0.36      0.32      0.34       471\n",
      "         3.0       0.63      0.69      0.66       420\n",
      "         4.0       0.63      0.75      0.68       491\n",
      "         5.0       0.74      0.66      0.70       532\n",
      "         6.0       1.00      0.92      0.96       537\n",
      "\n",
      "    accuracy                           0.65      2947\n",
      "   macro avg       0.64      0.64      0.64      2947\n",
      "weighted avg       0.65      0.65      0.64      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rfc_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decidedly worse - so as thought before, PCA for low dimensional dataset only makes it worse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whats with the jerk signals bit? esp the first derivative part?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.array([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 7, 8, 9, 10], [6, 7, 8, 9, 10, 6, 7, 8, 9, 10, 6, 7, 8, 9, 10], [6, 7, 8, 9, 10, 4, 5, 6, 7, 8, 6, 7, 8, 9, 10]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10,  6,  7,  8,  9, 10],\n",
       "       [ 6,  7,  8,  9, 10,  6,  7,  8,  9, 10,  6,  7,  8,  9, 10],\n",
       "       [ 6,  7,  8,  9, 10,  4,  5,  6,  7,  8,  6,  7,  8,  9, 10]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.33333333e+00,  1.00000000e+01,  1.00000000e+00,\n",
       "         2.74873708e+00, -4.45837546e-01, -9.02076125e-01,\n",
       "         4.00000000e+00,  2.33333333e+00,  8.95000000e+01,\n",
       "         6.64500000e+02],\n",
       "       [ 8.00000000e+00,  1.00000000e+01,  6.00000000e+00,\n",
       "         1.41421356e+00,  0.00000000e+00, -1.30000000e+00,\n",
       "         2.00000000e+00,  1.00000000e+00,  1.12000000e+02,\n",
       "         9.22000000e+02],\n",
       "       [ 7.33333333e+00,  1.00000000e+01,  4.00000000e+00,\n",
       "         1.69967317e+00, -1.20686852e-01, -7.65088757e-01,\n",
       "         2.50000000e+00,  1.33333333e+00,  1.02000000e+02,\n",
       "         7.82000000e+02]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_area_features(q, Te=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  3,  4,  5,  6,  7,  8,  9, 10,  6,  7,  8,  9, 10],\n",
       "       [ 7,  8,  9, 10,  6,  7,  8,  9, 10,  6,  7,  8,  9, 10],\n",
       "       [ 7,  8,  9, 10,  4,  5,  6,  7,  8,  6,  7,  8,  9, 10]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10,  6,  7,  8,  9],\n",
       "       [ 6,  7,  8,  9, 10,  6,  7,  8,  9, 10,  6,  7,  8,  9],\n",
       "       [ 6,  7,  8,  9, 10,  4,  5,  6,  7,  8,  6,  7,  8,  9]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  1,  1,  1,  1,  1,  1,  1, -4,  1,  1,  1,  1],\n",
       "       [ 1,  1,  1,  1, -4,  1,  1,  1,  1, -4,  1,  1,  1,  1],\n",
       "       [ 1,  1,  1,  1, -6,  1,  1,  1,  1, -2,  1,  1,  1,  1]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(q[:, 1:]-q[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = stat_area_features(q[:, 1:]-q[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.64285714,  1.        , -4.        ,  1.28769688, -3.32820118,\n",
       "         9.07692308,  0.        ,  0.35714286,  8.        , 28.        ],\n",
       "       [ 0.28571429,  1.        , -4.        ,  1.74963553, -2.04124145,\n",
       "         2.16666667,  0.        ,  0.71428571,  3.        , 43.        ],\n",
       "       [ 0.28571429,  1.        , -6.        ,  1.90595201, -2.64020432,\n",
       "         5.6143795 ,  0.        ,  0.71428571,  3.        , 51.        ]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# still lost about the use of Te here: esp in context below which does not work \n",
    "# features_xt_jerk = stat_area_features((x[:, 1:]-x[:, :-1])/Te, Te=Te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying without Te business and sees what it gives for raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol = stat_area_features(body_acc_x_train, Te=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.26869044e-03,  1.08102500e-02, -4.29425300e-03, ...,\n",
       "         2.44426240e-03,  2.89514201e-01,  1.76470832e-03],\n",
       "       [ 1.73739553e-04,  5.25084200e-03, -6.70614800e-03, ...,\n",
       "         9.99486447e-04,  2.24911623e-02,  5.04263828e-04],\n",
       "       [ 4.28091216e-04,  8.16653600e-03, -1.04828100e-02, ...,\n",
       "         1.73074978e-03,  5.19412136e-02,  1.09754309e-03],\n",
       "       ...,\n",
       "       [-8.63149109e-04,  6.62930500e-01, -3.95135000e-01, ...,\n",
       "         1.61759151e-01,  1.10483064e-01,  8.23674326e+00],\n",
       "       [ 2.48912541e-03,  7.01377900e-01, -4.13906100e-01, ...,\n",
       "         1.64010275e-01,  4.87184787e-01,  8.22770611e+00],\n",
       "       [ 1.52350776e-02,  8.12856600e-01, -4.13906100e-01, ...,\n",
       "         1.42122228e-01,  2.13282473e+00,  7.24051114e+00]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol_jerk = stat_area_features((body_acc_x_train[:, 1:]-body_acc_x_train[:, :-1])/1.0, Te=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.09814843e-05,  9.95770850e-03, -6.76514900e-03, ...,\n",
       "         9.82247484e-04, -4.48308850e-03,  4.60391132e-04],\n",
       "       [-2.12008110e-05,  5.27592377e-03, -5.53020420e-03, ...,\n",
       "         1.10281419e-03, -5.09195650e-03,  3.64013168e-04],\n",
       "       [-1.06583307e-05,  9.00938000e-03, -7.41563700e-03, ...,\n",
       "         1.48491073e-03, -2.60944000e-04,  7.45909893e-04],\n",
       "       ...,\n",
       "       [ 9.05724409e-05,  2.54225300e-01, -3.53026300e-01, ...,\n",
       "         5.91451876e-02, -2.70417000e-02,  1.25776991e+00],\n",
       "       [-1.63418528e-03,  3.39070600e-01, -3.24523700e-01, ...,\n",
       "         4.94311853e-02, -2.29172965e-01,  1.10208825e+00],\n",
       "       [ 1.84817323e-04,  4.38307700e-01, -4.39394790e-01, ...,\n",
       "         4.30934027e-02,  2.75327500e-02,  1.35522443e+00]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol_jerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
