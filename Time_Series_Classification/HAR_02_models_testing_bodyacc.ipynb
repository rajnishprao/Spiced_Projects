{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial for part of the SVM \n",
    "# with just basic statistical features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.stats as st\n",
    "from scipy.fftpack import fft, fftfreq\n",
    "from scipy.signal import argrelextrema\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load body acceleration raw signals \n",
    "# x axis\n",
    "X_train_x_raw = np.loadtxt('./HARDataset/train/Inertial Signals/body_acc_x_train.txt')\n",
    "X_test_x_raw = np.loadtxt('./HARDataset/test/Inertial Signals/body_acc_x_test.txt')\n",
    "\n",
    "# y axis\n",
    "X_train_y_raw = np.loadtxt('./HARDataset/train/Inertial Signals/body_acc_y_train.txt')\n",
    "X_test_y_raw = np.loadtxt('./HARDataset/test/Inertial Signals/body_acc_y_test.txt')\n",
    "\n",
    "# z axis\n",
    "X_train_z_raw = np.loadtxt('./HARDataset/train/Inertial Signals/body_acc_z_train.txt')\n",
    "X_test_z_raw = np.loadtxt('./HARDataset/test/Inertial Signals/body_acc_z_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 128), (2947, 128), (7352, 128), (2947, 128), (7352, 128), (2947, 128))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_x_raw.shape, X_test_x_raw.shape, X_train_y_raw.shape, X_test_y_raw.shape, X_train_z_raw.shape, X_test_z_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load label vectors\n",
    "y_train = np.loadtxt('./HARDataset/train/y_train.txt')\n",
    "y_test = np.loadtxt('./HARDataset/test/y_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352,), (2947,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['Walking', 'Walking upstairs', 'Walking downstairs', 'Sitting', 'Standing', 'Laying']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_area_features(x): #, Te=1.0):\n",
    "    # mean\n",
    "    mean_ts = np.mean(x, axis=1).reshape(-1, 1)\n",
    "    # max\n",
    "    max_ts = np.amax(x, axis=1).reshape(-1, 1)\n",
    "    # min\n",
    "    min_ts = np.amin(x, axis=1).reshape(-1, 1)\n",
    "    # std\n",
    "    std_ts = np.std(x, axis=1).reshape(-1, 1)\n",
    "    # skew\n",
    "    skew_ts = st.skew(x, axis=1).reshape(-1, 1)\n",
    "    # kurtosis\n",
    "    kurtosis_ts = st.kurtosis(x, axis=1).reshape(-1, 1)\n",
    "    # interquartile range\n",
    "    iqr_ts = st.iqr(x, axis=1).reshape(-1, 1)\n",
    "    # median absolute deviation\n",
    "    mad_ts = np.median(np.sort(abs(x - np.mean(x, axis=1).reshape(-1, 1)), axis=1), axis=1).reshape(-1, 1)\n",
    "    # area under curve\n",
    "    #area_ts = np.trapz(x, axis=1, dx=Te).reshape(-1, 1)\n",
    "    # area under curve ** 2\n",
    "    #sq_area_ts = np.mean(x ** 2, axis=1, dx=Te).reshape(-1, 1)\n",
    "    \n",
    "    return np.concatenate((mean_ts, max_ts, min_ts, std_ts, skew_ts, kurtosis_ts, iqr_ts, \n",
    "                           mad_ts), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whats with Te 1/50? \n",
    "\n",
    "X_train_x_raw_stats = stat_area_features(X_train_x_raw)#, Te=Te)\n",
    "X_train_y_raw_stats = stat_area_features(X_train_y_raw)\n",
    "X_train_z_raw_stats = stat_area_features(X_train_z_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 8), (7352, 8), (7352, 8))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_x_raw_stats.shape, X_train_y_raw_stats.shape, X_train_z_raw_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train_x_raw_stats, X_train_y_raw_stats, X_train_z_raw_stats), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 24)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_x_raw_stats = stat_area_features(X_test_x_raw)#, Te=Te)\n",
    "X_test_y_raw_stats = stat_area_features(X_test_y_raw)\n",
    "X_test_z_raw_stats = stat_area_features(X_test_z_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2947, 8), (2947, 8), (2947, 8))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_x_raw_stats.shape, X_test_y_raw_stats.shape, X_test_z_raw_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate((X_test_x_raw_stats, X_test_y_raw_stats, X_test_z_raw_stats), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2947, 24)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2947,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can one do a simple log reg first?\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6392818280739935"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_logreg = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.59      0.70      0.64       496\n",
      "         2.0       0.66      0.54      0.60       471\n",
      "         3.0       0.88      0.87      0.87       420\n",
      "         4.0       0.52      0.19      0.27       491\n",
      "         5.0       0.52      0.69      0.59       532\n",
      "         6.0       0.60      0.76      0.67       537\n",
      "\n",
      "    accuracy                           0.62      2947\n",
      "   macro avg       0.63      0.62      0.61      2947\n",
      "weighted avg       0.62      0.62      0.60      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6711099020674647"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.57      0.74      0.64       496\n",
      "         2.0       0.64      0.43      0.51       471\n",
      "         3.0       0.87      0.89      0.88       420\n",
      "         4.0       0.44      0.22      0.30       491\n",
      "         5.0       0.49      0.74      0.59       532\n",
      "         6.0       0.65      0.63      0.64       537\n",
      "\n",
      "    accuracy                           0.60      2947\n",
      "   macro avg       0.61      0.61      0.59      2947\n",
      "weighted avg       0.60      0.60      0.59      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfc = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.62      0.69      0.66       496\n",
      "         2.0       0.62      0.59      0.61       471\n",
      "         3.0       0.90      0.83      0.86       420\n",
      "         4.0       0.63      0.49      0.56       491\n",
      "         5.0       0.66      0.77      0.71       532\n",
      "         6.0       0.85      0.87      0.86       537\n",
      "\n",
      "    accuracy                           0.71      2947\n",
      "   macro avg       0.72      0.71      0.71      2947\n",
      "weighted avg       0.71      0.71      0.71      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay i got some basics working with just one set of file and a minimal set of statistical features \n",
    "# lemme first expand this to include all three axes of body acceleration data \n",
    "# would putting them all into pandas dataframes be the most sensible thing to do? \n",
    "# i am "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
