{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding correlation coefficients for raw signals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.stats as st\n",
    "from scipy.fftpack import fft, fftfreq\n",
    "from scipy.signal import argrelextrema\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load body acceleration raw signals \n",
    "# x axis\n",
    "bx_train = np.loadtxt('./HARDataset/train/Inertial Signals/body_acc_x_train.txt')\n",
    "bx_test = np.loadtxt('./HARDataset/test/Inertial Signals/body_acc_x_test.txt')\n",
    "# y axis\n",
    "by_train = np.loadtxt('./HARDataset/train/Inertial Signals/body_acc_y_train.txt')\n",
    "by_test = np.loadtxt('./HARDataset/test/Inertial Signals/body_acc_y_test.txt')\n",
    "# z axis\n",
    "bz_train = np.loadtxt('./HARDataset/train/Inertial Signals/body_acc_z_train.txt')\n",
    "bz_test = np.loadtxt('./HARDataset/test/Inertial Signals/body_acc_z_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load total acceleration raw signals \n",
    "# x axis\n",
    "tx_train = np.loadtxt('./HARDataset/train/Inertial Signals/total_acc_x_train.txt')\n",
    "tx_test = np.loadtxt('./HARDataset/test/Inertial Signals/total_acc_x_test.txt')\n",
    "# y axis\n",
    "ty_train = np.loadtxt('./HARDataset/train/Inertial Signals/total_acc_y_train.txt')\n",
    "ty_test = np.loadtxt('./HARDataset/test/Inertial Signals/total_acc_y_test.txt')\n",
    "# z axis\n",
    "tz_train = np.loadtxt('./HARDataset/train/Inertial Signals/total_acc_z_train.txt')\n",
    "tz_test = np.loadtxt('./HARDataset/test/Inertial Signals/total_acc_z_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load body gyroscope raw signals \n",
    "# x axis\n",
    "gx_train = np.loadtxt('./HARDataset/train/Inertial Signals/body_gyro_x_train.txt')\n",
    "gx_test = np.loadtxt('./HARDataset/test/Inertial Signals/body_gyro_x_test.txt')\n",
    "# y axis\n",
    "gy_train = np.loadtxt('./HARDataset/train/Inertial Signals/body_gyro_y_train.txt')\n",
    "gy_test = np.loadtxt('./HARDataset/test/Inertial Signals/body_gyro_y_test.txt')\n",
    "# z axis\n",
    "gz_train = np.loadtxt('./HARDataset/train/Inertial Signals/body_gyro_z_train.txt')\n",
    "gz_test = np.loadtxt('./HARDataset/test/Inertial Signals/body_gyro_z_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 128), (2947, 128))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx_train.shape, bx_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 128), (2947, 128))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_train.shape, tx_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 128), (2947, 128))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gx_train.shape, gx_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load label vectors\n",
    "y_train = np.loadtxt('./HARDataset/train/y_train.txt')\n",
    "y_test = np.loadtxt('./HARDataset/test/y_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352,), (2947,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['Walking', 'Walking upstairs', 'Walking downstairs', 'Sitting', 'Standing', 'Laying']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_area_features(x, Te=1.0):\n",
    "    # mean\n",
    "    mean_ts = np.mean(x, axis=1).reshape(-1, 1)\n",
    "    # max\n",
    "    max_ts = np.amax(x, axis=1).reshape(-1, 1)\n",
    "    # min\n",
    "    min_ts = np.amin(x, axis=1).reshape(-1, 1)\n",
    "    # std\n",
    "    std_ts = np.std(x, axis=1).reshape(-1, 1)\n",
    "    # skew\n",
    "    skew_ts = st.skew(x, axis=1).reshape(-1, 1)\n",
    "    # kurtosis\n",
    "    kurtosis_ts = st.kurtosis(x, axis=1).reshape(-1, 1)\n",
    "    # interquartile range\n",
    "    iqr_ts = st.iqr(x, axis=1).reshape(-1, 1)\n",
    "    # median absolute deviation\n",
    "    mad_ts = np.median(np.sort(abs(x - np.mean(x, axis=1).reshape(-1, 1)), axis=1), axis=1).reshape(-1, 1)\n",
    "    # area under curve\n",
    "    area_ts = np.trapz(x, axis=1, dx=Te).reshape(-1, 1)\n",
    "    # area under curve ** 2\n",
    "    sq_area_ts = np.trapz(x ** 2, axis=1, dx=Te).reshape(-1, 1)\n",
    "    \n",
    "    return np.concatenate((mean_ts, max_ts, min_ts, std_ts, skew_ts, kurtosis_ts, iqr_ts, \n",
    "                           mad_ts, area_ts, sq_area_ts), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx_train_stats = stat_area_features(bx_train)\n",
    "by_train_stats = stat_area_features(by_train)\n",
    "bz_train_stats = stat_area_features(bz_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 10), (7352, 10), (7352, 10))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx_train_stats.shape, by_train_stats.shape, bz_train_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_train_stats = stat_area_features(tx_train)\n",
    "ty_train_stats = stat_area_features(ty_train)\n",
    "tz_train_stats = stat_area_features(tz_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 10), (7352, 10), (7352, 10))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_train_stats.shape, ty_train_stats.shape, tz_train_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gx_train_stats = stat_area_features(gx_train)\n",
    "gy_train_stats = stat_area_features(gy_train)\n",
    "gz_train_stats = stat_area_features(gz_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 10), (7352, 10), (7352, 10))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gx_train_stats.shape, gy_train_stats.shape, gz_train_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx_test_stats = stat_area_features(bx_test)\n",
    "by_test_stats = stat_area_features(by_test)\n",
    "bz_test_stats = stat_area_features(bz_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2947, 10), (2947, 10), (2947, 10))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx_test_stats.shape, by_test_stats.shape, bz_test_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_test_stats = stat_area_features(tx_test)\n",
    "ty_test_stats = stat_area_features(ty_test)\n",
    "tz_test_stats = stat_area_features(tz_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2947, 10), (2947, 10), (2947, 10))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_test_stats.shape, ty_test_stats.shape, tz_test_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gx_test_stats = stat_area_features(gx_test)\n",
    "gy_test_stats = stat_area_features(gy_test)\n",
    "gz_test_stats = stat_area_features(gz_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2947, 10), (2947, 10), (2947, 10))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gx_test_stats.shape, gy_test_stats.shape, gz_test_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jerk for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx_train_jerk = stat_area_features((bx_train[:, 1:] - bx_train[:, :-1])/1.0)\n",
    "by_train_jerk = stat_area_features((by_train[:, 1:] - by_train[:, :-1])/1.0)\n",
    "bz_train_jerk = stat_area_features((bz_train[:, 1:] - bz_train[:, :-1])/1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 10), (7352, 10), (7352, 10))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx_train_jerk.shape, by_train_jerk.shape, bz_train_jerk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_train_jerk = stat_area_features((tx_train[:, 1:] - tx_train[:, :-1])/1.0)\n",
    "ty_train_jerk = stat_area_features((ty_train[:, 1:] - ty_train[:, :-1])/1.0)\n",
    "tz_train_jerk = stat_area_features((tz_train[:, 1:] - tz_train[:, :-1])/1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 10), (7352, 10), (7352, 10))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_train_jerk.shape, ty_train_jerk.shape, tz_train_jerk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gx_train_jerk = stat_area_features((gx_train[:, 1:] - gx_train[:, :-1])/1.0)\n",
    "gy_train_jerk = stat_area_features((gy_train[:, 1:] - gy_train[:, :-1])/1.0)\n",
    "gz_train_jerk = stat_area_features((gz_train[:, 1:] - gz_train[:, :-1])/1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 10), (7352, 10), (7352, 10))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gx_train_jerk.shape, gy_train_jerk.shape, gz_train_jerk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jerk for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx_test_jerk = stat_area_features((bx_test[:, 1:] - bx_test[:, :-1])/1.0)\n",
    "by_test_jerk = stat_area_features((by_test[:, 1:] - by_test[:, :-1])/1.0)\n",
    "bz_test_jerk = stat_area_features((bz_test[:, 1:] - bz_test[:, :-1])/1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2947, 10), (2947, 10), (2947, 10))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx_test_jerk.shape, by_test_jerk.shape, bz_test_jerk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_test_jerk = stat_area_features((tx_test[:, 1:] - tx_test[:, :-1])/1.0)\n",
    "ty_test_jerk = stat_area_features((ty_test[:, 1:] - ty_test[:, :-1])/1.0)\n",
    "tz_test_jerk = stat_area_features((tz_test[:, 1:] - tz_test[:, :-1])/1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2947, 10), (2947, 10), (2947, 10))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_test_jerk.shape, ty_test_jerk.shape, tz_test_jerk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gx_test_jerk = stat_area_features((gx_test[:, 1:] - gx_test[:, :-1])/1.0)\n",
    "gy_test_jerk = stat_area_features((gy_test[:, 1:] - gy_test[:, :-1])/1.0)\n",
    "gz_test_jerk = stat_area_features((gz_test[:, 1:] - gz_test[:, :-1])/1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2947, 10), (2947, 10), (2947, 10))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gx_test_jerk.shape, gy_test_jerk.shape, gz_test_jerk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_domain_features(x, Te=1.0):\n",
    "    \n",
    "    # as DFT coefficients and their corresponding frequencies are symetrical arrays with respect to\n",
    "    # the middle of the array, need to control for whether samples in x are odd or even to then split arrays\n",
    "    if x.shape[1]%2 == 0:\n",
    "        N = int(x.shape[1]/2)\n",
    "    else: \n",
    "        N = int(x.shape[1]/2) - 1\n",
    "    xf = np.repeat(fftfreq(x.shape[1], d=1.0)[:N].reshape(1, -1), x.shape[0], axis=0) # frequencies\n",
    "    dft = np.abs(fft(x, axis=1))[:, :N] # DFT coefficients\n",
    "    \n",
    "    # stat and area features\n",
    "    dft_features = stat_area_features(dft)\n",
    "    # weighted mean freq\n",
    "    dft_weighted_mean_f = np.average(xf, axis=1, weights=dft).reshape(-1, 1)\n",
    "    # first 5 DFT coefficients\n",
    "    dft_first_coeff = dft[:, :5]\n",
    "    # first 5 local maxima of DFT coefficients and their corresponding frequencies\n",
    "    dft_max_coeff = np.zeros((x.shape[0], 5))\n",
    "    dft_max_coeff_f = np.zeros((x.shape[0], 5))\n",
    "    for row in range(x.shape[0]):\n",
    "        # find indexes of all local maximas\n",
    "        extrema_indiv = argrelextrema(dft[row, :], np.greater, axis=0)\n",
    "        # make list of tuples (DFT_i, f_i) of all local maxima\n",
    "        extrema_row = sorted([(dft[row, :][j], xf[row, j]) for j in extrema_indiv[0]],\n",
    "                             key=operator.itemgetter(0), reverse=True)[:5]\n",
    "        for i, ext in enumerate(extrema_row):\n",
    "            dft_max_coeff[row, i] = ext[0]\n",
    "            dft_max_coeff_f[row, i] = ext[1]\n",
    "    \n",
    "    return np.concatenate((dft_features, dft_weighted_mean_f, dft_first_coeff, \n",
    "                           dft_max_coeff, dft_max_coeff_f), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dft for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx_train_dft = frequency_domain_features(bx_train)\n",
    "by_train_dft = frequency_domain_features(by_train)\n",
    "bz_train_dft = frequency_domain_features(bz_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 26), (7352, 26), (7352, 26))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx_train_dft.shape, by_train_dft.shape, bz_train_dft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_train_dft = frequency_domain_features(tx_train)\n",
    "ty_train_dft = frequency_domain_features(ty_train)\n",
    "tz_train_dft = frequency_domain_features(tz_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 26), (7352, 26), (7352, 26))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_train_dft.shape, ty_train_dft.shape, tz_train_dft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "gx_train_dft = frequency_domain_features(gx_train)\n",
    "gy_train_dft = frequency_domain_features(gy_train)\n",
    "gz_train_dft = frequency_domain_features(gz_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 26), (7352, 26), (7352, 26))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gx_train_dft.shape, gy_train_dft.shape, gz_train_dft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dft for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx_test_dft = frequency_domain_features(bx_test)\n",
    "by_test_dft = frequency_domain_features(by_test)\n",
    "bz_test_dft = frequency_domain_features(bz_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2947, 26), (2947, 26), (2947, 26))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx_test_dft.shape, by_test_dft.shape, bz_test_dft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_test_dft = frequency_domain_features(tx_test)\n",
    "ty_test_dft = frequency_domain_features(ty_test)\n",
    "tz_test_dft = frequency_domain_features(tz_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2947, 26), (2947, 26), (2947, 26))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_test_dft.shape, ty_test_dft.shape, tz_test_dft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "gx_test_dft = frequency_domain_features(gx_test)\n",
    "gy_test_dft = frequency_domain_features(gy_test)\n",
    "gz_test_dft = frequency_domain_features(gz_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2947, 26), (2947, 26), (2947, 26))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gx_test_dft.shape, gy_test_dft.shape, gz_test_dft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dft_jerk for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx_train_dft_jerk = frequency_domain_features((bx_train[:, 1:] - bx_train[:, :-1])/1.0)\n",
    "by_train_dft_jerk = frequency_domain_features((by_train[:, 1:] - by_train[:, :-1])/1.0)\n",
    "bz_train_dft_jerk = frequency_domain_features((bz_train[:, 1:] - bz_train[:, :-1])/1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 26), (7352, 26), (7352, 26))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx_train_dft_jerk.shape, by_train_dft_jerk.shape, bz_train_dft_jerk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_train_dft_jerk = frequency_domain_features((tx_train[:, 1:] - tx_train[:, :-1])/1.0)\n",
    "ty_train_dft_jerk = frequency_domain_features((ty_train[:, 1:] - ty_train[:, :-1])/1.0)\n",
    "tz_train_dft_jerk = frequency_domain_features((tz_train[:, 1:] - tz_train[:, :-1])/1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 26), (7352, 26), (7352, 26))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_train_dft_jerk.shape, ty_train_dft_jerk.shape, tz_train_dft_jerk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "gx_train_dft_jerk = frequency_domain_features((gx_train[:, 1:] - gx_train[:, :-1])/1.0)\n",
    "gy_train_dft_jerk = frequency_domain_features((gy_train[:, 1:] - gy_train[:, :-1])/1.0)\n",
    "gz_train_dft_jerk = frequency_domain_features((gz_train[:, 1:] - gz_train[:, :-1])/1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 26), (7352, 26), (7352, 26))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gx_train_dft_jerk.shape, gy_train_dft_jerk.shape, gz_train_dft_jerk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dft_jerk for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx_test_dft_jerk = frequency_domain_features((bx_test[:, 1:] - bx_test[:, :-1])/1.0)\n",
    "by_test_dft_jerk = frequency_domain_features((by_test[:, 1:] - by_test[:, :-1])/1.0)\n",
    "bz_test_dft_jerk = frequency_domain_features((bz_test[:, 1:] - bz_test[:, :-1])/1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2947, 26), (2947, 26), (2947, 26))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx_test_dft_jerk.shape, by_test_dft_jerk.shape, bz_test_dft_jerk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_test_dft_jerk = frequency_domain_features((tx_test[:, 1:] - tx_test[:, :-1])/1.0)\n",
    "ty_test_dft_jerk = frequency_domain_features((ty_test[:, 1:] - ty_test[:, :-1])/1.0)\n",
    "tz_test_dft_jerk = frequency_domain_features((tz_test[:, 1:] - tz_test[:, :-1])/1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2947, 26), (2947, 26), (2947, 26))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_test_dft_jerk.shape, ty_test_dft_jerk.shape, tz_test_dft_jerk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "gx_test_dft_jerk = frequency_domain_features((gx_test[:, 1:] - gx_test[:, :-1])/1.0)\n",
    "gy_test_dft_jerk = frequency_domain_features((gy_test[:, 1:] - gy_test[:, :-1])/1.0)\n",
    "gz_test_dft_jerk = frequency_domain_features((gz_test[:, 1:] - gz_test[:, :-1])/1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2947, 26), (2947, 26), (2947, 26))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gx_test_dft_jerk.shape, gy_test_dft_jerk.shape, gz_test_dft_jerk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation coefficients for raw signals between axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_coeffs(x, y, z):\n",
    "    corr = np.empty((x.shape[0], 3))\n",
    "    for row in range(x.shape[0]):\n",
    "        xyz_matrix = np.concatenate((x[row, :].reshape(1, -1), y[row, :].reshape(1, -1), \n",
    "                                     z[row, :].reshape(1, -1)), axis=0)\n",
    "        corr[row, 0] = np.corrcoef(xyz_matrix)[0, 1]\n",
    "        corr[row, 1] = np.corrcoef(xyz_matrix)[0, 2]\n",
    "        corr[row, 2] = np.corrcoef(xyz_matrix)[1, 2]\n",
    "        \n",
    "    return corr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_b_train = corr_coeffs(bx_train, by_train, bz_train)\n",
    "corr_t_train = corr_coeffs(tx_train, ty_train, tz_train)\n",
    "corr_g_train = corr_coeffs(gx_train, gy_train, gz_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 3), (7352, 3), (7352, 3))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_b_train.shape, corr_t_train.shape, corr_g_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_b_test = corr_coeffs(bx_test, by_test, bz_test)\n",
    "corr_t_test = corr_coeffs(tx_test, ty_test, tz_test)\n",
    "corr_g_test = corr_coeffs(gx_test, gy_test, gz_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2947, 3), (2947, 3), (2947, 3))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_b_test.shape, corr_t_test.shape, corr_g_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating X_train and X_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((bx_train_stats, by_train_stats, bz_train_stats, \n",
    "                          tx_train_stats, ty_train_stats, tz_train_stats, \n",
    "                          gx_train_stats, gy_train_stats, gz_train_stats, \n",
    "                          bx_train_jerk, by_train_jerk, bz_train_jerk, \n",
    "                          tx_train_jerk, ty_train_jerk, tz_train_jerk, \n",
    "                          gx_train_jerk, gy_train_jerk, gz_train_jerk,\n",
    "                          bx_train_dft, by_train_dft, bz_train_dft, \n",
    "                          tx_train_dft, ty_train_dft, tz_train_dft, \n",
    "                          gx_train_dft, gy_train_dft, gz_train_dft, \n",
    "                          bx_train_dft_jerk, by_train_dft_jerk, bz_train_dft_jerk, \n",
    "                          tx_train_dft_jerk, ty_train_dft_jerk, tz_train_dft_jerk, \n",
    "                          gx_train_dft_jerk, gy_train_dft_jerk, gz_train_dft_jerk, \n",
    "                          corr_b_train, corr_t_train, corr_g_train), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate((bx_test_stats, by_test_stats, bz_test_stats, \n",
    "                          tx_test_stats, ty_test_stats, tz_test_stats, \n",
    "                          gx_test_stats, gy_test_stats, gz_test_stats, \n",
    "                          bx_test_jerk, by_test_jerk, bz_test_jerk, \n",
    "                          tx_test_jerk, ty_test_jerk, tz_test_jerk, \n",
    "                          gx_test_jerk, gy_test_jerk, gz_test_jerk,\n",
    "                          bx_test_dft, by_test_dft, bz_test_dft, \n",
    "                          tx_test_dft, ty_test_dft, tz_test_dft, \n",
    "                          gx_test_dft, gy_test_dft, gz_test_dft, \n",
    "                          bx_test_dft_jerk, by_test_dft_jerk, bz_test_dft_jerk, \n",
    "                          tx_test_dft_jerk, ty_test_dft_jerk, tz_test_dft_jerk, \n",
    "                          gx_test_dft_jerk, gy_test_dft_jerk, gz_test_dft_jerk, \n",
    "                          corr_b_test, corr_t_test, corr_g_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 657), (2947, 657))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling data makes big differnce! to all! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can one do a simple log reg first?\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9917029379760609"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train, y_train) # adding corr: 0.99 to 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_logreg = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.97      0.96      0.97       496\n",
      "         2.0       0.98      0.96      0.97       471\n",
      "         3.0       0.96      0.98      0.97       420\n",
      "         4.0       0.87      0.91      0.89       491\n",
      "         5.0       0.93      0.87      0.90       532\n",
      "         6.0       0.99      1.00      0.99       537\n",
      "\n",
      "    accuracy                           0.95      2947\n",
      "   macro avg       0.95      0.95      0.95      2947\n",
      "weighted avg       0.95      0.95      0.95      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_logreg)) # adding corr accuracy: 0.95 to 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9857181719260065"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X_train, y_train) # adding corr 0.9838 to 0.9857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.99      0.98      0.99       496\n",
      "         2.0       0.99      0.99      0.99       471\n",
      "         3.0       0.98      0.98      0.98       420\n",
      "         4.0       0.90      0.89      0.90       491\n",
      "         5.0       0.91      0.90      0.91       532\n",
      "         6.0       0.99      1.00      1.00       537\n",
      "\n",
      "    accuracy                           0.96      2947\n",
      "   macro avg       0.96      0.96      0.96      2947\n",
      "weighted avg       0.96      0.96      0.96      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_svm)) # adding corr 0.96 to 0.96 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_train, y_train) # 1.0 already without corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfc = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.98      0.95      0.97       496\n",
      "         2.0       0.89      0.97      0.93       471\n",
      "         3.0       0.93      0.86      0.90       420\n",
      "         4.0       0.86      0.97      0.91       491\n",
      "         5.0       0.96      0.86      0.91       532\n",
      "         6.0       1.00      1.00      1.00       537\n",
      "\n",
      "    accuracy                           0.94      2947\n",
      "   macro avg       0.94      0.93      0.93      2947\n",
      "weighted avg       0.94      0.94      0.94      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rfc)) # adding corr 0.92 to 0.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding corr led to marginal improvements but nothing dramatic\n",
    "# things look good so far\n",
    "# code is still very repetitive and can be cleaned up with functions to load 3 sets of data and run in parallel\n",
    "# will create one final file with just SVM analysis and run hyperparamter optimization and add a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
