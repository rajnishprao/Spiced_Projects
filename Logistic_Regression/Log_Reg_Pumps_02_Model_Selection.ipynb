{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing various logistic regression models on pumps dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import linear_model \n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 39), (59400, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data\n",
    "\n",
    "train_features = pd.read_csv('X_train_pumps.csv', index_col=0)\n",
    "train_labels = pd.read_csv('y_train_pumps.csv', index_col=0)\n",
    "\n",
    "train_features.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14850, 39)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data\n",
    "\n",
    "test_features = pd.read_csv('X_test_pumps.csv', index_col=0)\n",
    "\n",
    "test_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data wrangling/feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_data(df):\n",
    "    # drop columns that do not appear to provide no obvious information or are repetitive \n",
    "    df = df.drop(['funder', 'installer','date_recorded', 'wpt_name', 'num_private', 'subvillage','region_code',\n",
    "                  'lga', 'ward', 'public_meeting', 'recorded_by','scheme_management', 'scheme_name', \n",
    "                  'permit','extraction_type', 'extraction_type_group', 'management', 'management_group',\n",
    "                  'payment', 'water_quality', 'quantity', 'source', 'source_class', \n",
    "                  'waterpoint_type_group','construction_year'], axis=1)\n",
    "    \n",
    "    # dummies for categorical columns\n",
    "    dummy_list = ['basin', 'region','district_code','extraction_type_class','payment_type','quality_group',\n",
    "                  'quantity_group','source_type','waterpoint_type']\n",
    "    for each in dummy_list:\n",
    "        try:\n",
    "            df = pd.get_dummies(data=df, prefix=dummy_list, columns=dummy_list, drop_first=True)\n",
    "        except:\n",
    "            Exception\n",
    "            continue\n",
    "            \n",
    "    # longtitide: replacing 0 with mean \n",
    "    df['longitude'].replace(0.000000, 34.213823, inplace=True)\n",
    "    \n",
    "    # MinMax Scaling of numerical columns\n",
    "    scale = MinMaxScaler()\n",
    "    \n",
    "    amount_tsh_scaled = scale.fit_transform(df[['amount_tsh']])\n",
    "    df['amount_tsh_scaled'] = amount_tsh_scaled\n",
    "    df = df.drop(['amount_tsh'], axis=1)\n",
    "    \n",
    "    gps_height_scaled = scale.fit_transform(df[['gps_height']])\n",
    "    df['gps_height_scaled'] = gps_height_scaled\n",
    "    df = df.drop(['gps_height'], axis=1)\n",
    "    \n",
    "    longitude_scaled = scale.fit_transform(df[['longitude']])\n",
    "    df['longitude_scaled'] = longitude_scaled\n",
    "    df = df.drop(['longitude'], axis=1)\n",
    "    \n",
    "    latitude_scaled = scale.fit_transform(df[['latitude']])\n",
    "    df['latitude_scaled'] = latitude_scaled\n",
    "    df = df.drop(['latitude'], axis=1)\n",
    "    \n",
    "    population_scaled = scale.fit_transform(df[['population']])\n",
    "    df['population_scaled'] = population_scaled\n",
    "    df = df.drop(['population'], axis=1)\n",
    "    \n",
    "    return df     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = wrangle_data(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = wrangle_data(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 85), (14850, 85))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# both data sets have same number of features \n",
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 85), (59400, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_features\n",
    "y = train_labels\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47520, 85), (11880, 85), (47520, 1), (11880, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression: test accuracy - 0.73\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_logreg = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_train_score = logreg.score(X_train, y_train)\n",
    "logreg_test_acc = accuracy_score(y_test, y_pred_logreg)\n",
    "logreg_test_precision = precision_score(y_test, y_pred_logreg, average='weighted')\n",
    "logreg_test_recall = recall_score(y_test, y_pred_logreg, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.71      0.91      0.79      6457\n",
      "functional needs repair       0.55      0.07      0.12       851\n",
      "         non functional       0.79      0.60      0.68      4572\n",
      "\n",
      "               accuracy                           0.73     11880\n",
      "              macro avg       0.68      0.53      0.53     11880\n",
      "           weighted avg       0.73      0.73      0.70     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Classifier: test accuracy - 0.79\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_score = rf.score(X_train, y_train)\n",
    "rf_test_acc = accuracy_score(y_test, y_pred_rf)\n",
    "rf_test_precision = precision_score(y_test, y_pred_rf, average='weighted')\n",
    "rf_test_recall = recall_score(y_test, y_pred_rf, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.80      0.86      0.83      6457\n",
      "functional needs repair       0.49      0.34      0.40       851\n",
      "         non functional       0.81      0.78      0.79      4572\n",
      "\n",
      "               accuracy                           0.79     11880\n",
      "              macro avg       0.70      0.66      0.68     11880\n",
      "           weighted avg       0.78      0.79      0.78     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
       "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
       "              random_state=None, shuffle=True, tol=None,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stochastic Gradient Descent Classifier: test accuracy - 0.72\n",
    "\n",
    "sgd = SGDClassifier(max_iter=5, tol=None)\n",
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sgd = sgd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_train_score = sgd.score(X_train, y_train)\n",
    "sgd_test_acc = accuracy_score(y_test, y_pred_sgd)\n",
    "sgd_test_precision = precision_score(y_test, y_pred_sgd, average='weighted')\n",
    "sgd_test_recall = recall_score(y_test, y_pred_sgd, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.69      0.93      0.79      6457\n",
      "functional needs repair       0.36      0.02      0.03       851\n",
      "         non functional       0.81      0.57      0.67      4572\n",
      "\n",
      "               accuracy                           0.72     11880\n",
      "              macro avg       0.62      0.50      0.50     11880\n",
      "           weighted avg       0.72      0.72      0.69     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Support Vector Classifier: test accuracy - 0.73 (why this version of SVC?)\n",
    "\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_linear_svc = linear_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc_train_score = linear_svc.score(X_train, y_train)\n",
    "linear_svc_test_acc = accuracy_score(y_test, y_pred_linear_svc)\n",
    "linear_svc_test_precision = precision_score(y_test, y_pred_linear_svc, average='weighted')\n",
    "linear_svc_test_recall = recall_score(y_test, y_pred_linear_svc, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.70      0.92      0.79      6457\n",
      "functional needs repair       0.00      0.00      0.00       851\n",
      "         non functional       0.80      0.59      0.68      4572\n",
      "\n",
      "               accuracy                           0.73     11880\n",
      "              macro avg       0.50      0.50      0.49     11880\n",
      "           weighted avg       0.69      0.73      0.69     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_linear_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree Classifier: test accuracy - 0.75\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train_score = dt.score(X_train, y_train)\n",
    "dt_test_acc = accuracy_score(y_test, y_pred_dt)\n",
    "dt_test_precision = precision_score(y_test, y_pred_dt, average='weighted')\n",
    "dt_test_recall = recall_score(y_test, y_pred_dt, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.79      0.79      0.79      6457\n",
      "functional needs repair       0.36      0.38      0.37       851\n",
      "         non functional       0.76      0.76      0.76      4572\n",
      "\n",
      "               accuracy                           0.75     11880\n",
      "              macro avg       0.64      0.64      0.64     11880\n",
      "           weighted avg       0.75      0.75      0.75     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.993540</td>\n",
       "      <td>0.789141</td>\n",
       "      <td>0.782550</td>\n",
       "      <td>0.789141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.993582</td>\n",
       "      <td>0.748316</td>\n",
       "      <td>0.750727</td>\n",
       "      <td>0.748316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.731376</td>\n",
       "      <td>0.729798</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVC</th>\n",
       "      <td>0.727315</td>\n",
       "      <td>0.727609</td>\n",
       "      <td>0.687326</td>\n",
       "      <td>0.727609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD Classifier</th>\n",
       "      <td>0.724832</td>\n",
       "      <td>0.724832</td>\n",
       "      <td>0.716047</td>\n",
       "      <td>0.724832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Training Score  Accuracy  Precision    Recall\n",
       "Model                                                                  \n",
       "Random Forest Classifier        0.993540  0.789141   0.782550  0.789141\n",
       "Decision Tree                   0.993582  0.748316   0.750727  0.748316\n",
       "Logistic Regression             0.731376  0.729798   0.727600  0.729798\n",
       "Linear SVC                      0.727315  0.727609   0.687326  0.727609\n",
       "SGD Classifier                  0.724832  0.724832   0.716047  0.724832"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary of results\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Model':['Logistic Regression', 'Random Forest Classifier', 'SGD Classifier', \n",
    "              'Linear SVC', 'Decision Tree'],\n",
    "    'Training Score':[logreg_train_score, rf_train_score, sgd_train_score,\n",
    "                      linear_svc_train_score, dt_train_score],\n",
    "    'Accuracy':[logreg_test_acc, rf_test_acc, sgd_test_acc, linear_svc_test_acc, dt_test_acc],\n",
    "    'Precision':[logreg_test_precision, rf_test_precision, sgd_test_precision, linear_svc_test_precision,\n",
    "                 dt_test_precision],\n",
    "    'Recall':[logreg_test_recall, rf_test_recall, sgd_test_recall, linear_svc_test_recall, dt_test_recall]})\n",
    "results_df = results.sort_values(by='Accuracy', ascending=False)\n",
    "results_df = results_df.set_index('Model')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attn: accuracy, precision and recall values here are weighted averages of all the 3 classes \n",
    "# for individual classes, refer to classification reports above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall, Random Forest Classifiers appears to be the best\n",
    "# Will use this for subsequent analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
